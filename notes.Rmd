---
title: "notes"
author: "Colby Reichenbach"
date: "2024-02-16"
output: html_document
---
Notes
Moral machine learning
Partition 
-	70 - 90% training data, 30-10% testing data
-	Compass decision fails in favor of white over black.
Data privacy
-	Consent v informed consent.
Precise interpretation
-	Correlation v causation
-	Simpsons paradox – perceived trend among population (large group of data) can flip or cease to exist when looking at sub populations (smaller set of data).
-	Confounding var. effects explanatory variable but not explanatory variable itself
-	Latent batch effects
Accountability for black box
-	Reproducibility
-	High levels of accountability cand interpretability
Parliament AI act

What seems most important of the justifications for next class?”

Lecture 2
Consequentialism: framework posits the justifiability of an action is actively determine by consequences

Utilitarianism: a type of consequentialism that claims that right action is the one with the best consequences – best maximizes pleasure and minimizes pain

Thought experiment: trolly problem
Stay course doctrine of double effect
Classical utilities commits are impartiality every person interests matter the same
So called “act” and “rule” Utilitarianism
Act Utilitarianism considers justifiability of a single action based on consequences in a case-by-case scenario
Rule Utilitarianism: if a rule permitting an action nets pain that action is not permissible – broader class of actions
Appealing qualities of Utilitarianism:
1.)	Distills morality into numbers game
2.)	Impartial
3.)	Pairs 1 and 2 – closest to objective
Data privacy: trade off bn efficiency and equity
Moral luck: if all we care about it consequences, we may be forced to applaud to commend someone for their mal intended but benign in consequence actions

Lecture 3
Deontology: study of the nature duty and obligation
Universal maxim: an action is correct only if you can universalize it
Ends not means: action correct/justifiable if insofar as it at all times treats moral agents as ends and never merely meets
Must fulfill both to be moral
Deontology upsides
1.	Circumvents moral luck
Intentions more than consequences more in our control
2.	Provides a steadfast principle limit our slippery slope tendencies – mitigates it
3.	Protects individual liberties in a way that consequentialism does not
Ground obligations
Best case scenario – sentience – resolves below, resides in a spectrum
Kant – rationality, too narrow bc excludes groups of people - (toddlers very elderly etc. not completely rational yet)/ moral agents. Could also be too broad (extended to computers/ai)
Self awareness – too narrow


Compass – false negatives/positives – but what does that mean for the jury that already has false negatives and positives, though they hold sentience does that play a role in their false “accusations” which would be better off done by computer to stop that from happening. In other words which is a better action?

Lecture 4
Virtue: an excellent character trait qualities conductive to flourishing / a good life – ex honesty, respect, etc
Virtue ethics: an action is correct/justifiable if in accordance w virtue
-	Aristotle: virtues are means bn extremes (vices)
Upshot: virtue ethics is able to circumvent moral luck
Appealing qualities of virtue:
1.	Flexibility – can be honest without being forthcoming
2.	Can be cultivated/ learned – luck involved Susan Wolfe – ex born into certain environments such as war some virtues are going to be a lot harder/ impossible to learn
3.	At times virtue can encompass both consequentialism and deontology but it is never reduced to either of them – 
Complication: virtues can conflict!
Algorithmic bias – ex compass data set
Discriminatory is to a bad thing – it is necessary to classify things – it only becomes a problem when it is arbitrary discrimination ie BIAS

Lecture 5 – criticisms of deontology absent

Lecture 6 - Virtue ethics criticisms
Objections
1.	Does it actually provide action-guidance
-	Not all specific, is on a spectrum – grey areas
2.	Virtues are time specific
-	Time specific – so no moral absolutes more of moral relativity
-	Moral subjective not objective?
3.	Define virtuous person virtuous and we have circular reasoning
-	Somebody who carries out virtuous act
-	Act? One that a virtuous person would do under similar circumstances
-	ie have to define one to define the other
Morality subjective or objective?
-	Subjective is person specific – the obj cannot be referenced independent of the subject
-	Objective not person/context specific – exists independent of reference to individual
Objectivity arguments – 
-	Moral values are absolute, but each person’s interpretations of them are
-	Biologically linked (could be naturalistic fallacy) – Phineas gage – frontal lobe destroyed
Subjectivity arguments – 
-	No moral absolutes w/o heavy qualifications and specifications to the subject – ex self-defense killing

Lecture 5: 1/29/24
Justify: offering a set reason in favor of a claim that other rational humans could not reasonably refute
Reason: consideration in favor of a claim
Reasons are not… intuitions, gut instinct, not reducible to our desires.
What does reasons buy us in terms of justifiability? – it is refutable?
Does justifiability need consensus?
-	Plurality/majority
-	Popularity of interpretation does not mean justifiable
What happens when statistical justifiability and moral justifiability conflict?
-	Rare occurrence
-	Int the instance where they do come into conflict morality prerequisite to statistics

Patient situation like we discussed before in class, have to compromise and either decide against the statistical answer and the moral answer

Morality is a prerequisite of statistics
Training v test data – if training data set is not representative of test set


Lecture 2/16
Support vector machine (SVM)
-	Find line that separates classes
-	Chooses line that maximizes margin – most generalized line
-	“max the main distance” – in d dimensions – d-1 dimensional hyperplane
-	W and x normal vectors
-	W^T (x) + b = 0
-	A1x1+a2x2=a…x… +b = 0
-	B is offset
-	D= |b|/||w||2 = |b|/sqrt(a12+a22 +an2)
-	Distance bn a given pt and place
-	D = |coordinate values/||w||2
SVM optimization problem: 
Distance dh bn vector phi(x0) and the hyperplane wT phi(X) + b
DH = |WT(phi(X0)) + b| / ||w||2

W* = argmax[min distance (phi(Xn))]  -  not linear or convect
To solve it would have to recast (maximize margin) it in its dual – to make quadratic
Not classifying algorithm by itself

A1*X1 + … > 0 one class
A1*X1 + … < 0 different class

Assumption: data is linearly separable – if not there is not hyperplane

Bottle example – cutting board separates bottles but no linear placement separates classes

What to do? Project it to higher dimension
Now can do horizontal lines – class of bottles shorter than other class
Problem? Higher dimensions are much harder to compute

Kernel trick: embed in higher dimension – use kernel fxn to not have to compute coordinates in a lower dimension ambient space

Kernel: if we have Y,ZeX and phi: X  Rn
K(y,z) = <phi(y),phi(z)> = phi(y)Tphi(z)

Ex x,yeR2, phi: R2  R3
Phi(z) = (Z12, sqrt(2) z1z2 , z22 , phi (x) same but w x

K(x,y) < phi(x), phi(y)> = phi(x)T phi(y) = [ x12  sqrt(2) x1x2 x22]

X12 y12 + sqrt(2) x1x2sqrt(2)y1y2 + x22y22
X12 y12 + 2 x1x2y1y2 + x22y22
X1y1+x2y2
[(x1 x2) (y1 y2]2
[XTY]^2 – only in R2 so got us from 3 dto 2d


Linear XTY
Poly [XTy+b]d
Radid exp(-||x-y|2/gamma)

Lecture 02/21
Decesion tree
- an undirected graph G(E,V) that satisfies one of 4 equivalent (satisfies all 4)
1. G is connected but acyclic - no loops
2. G is a cyclic - simple cylce created by adding a simple edge
3. G is disconnected if remove single edge
4. Any two nodes in G can be connected via a unique simple path
Classification tree
- a binary tree that partitions the data according to features that well seperate the classes, we reach purity with terminal nodes

Gini index: if p-hat is training sample prop of observatoins in the mth node of the kth class then G = P-hat * m(1- P-hat)
g = value bn (0 to .5)

x~Bin(n,p) Var[X] = np(1-p)

Cross-entropy
Dmk = -Z p-hat log(p-hat)

Gini index usually quickly, more efficent, no computing algorithm, marignally more predicitivce through misclassification error rate - usually use with large data sets
Cross entropy usually use with small data set

How do tou know when to stop - in order to not overfit?
Pruning - balance complexity and fit to make a well performing, general model
misclassification error: E = 1- max(p-hat)

Optimal sparse DTs
min( C(X,Y,T) + lambda complexity(T) )

Implemening trees - not just for algorithmic bias, but also calrity as to how classification works - like how it gets there

2/23/24
Decision tree code
Classification v regression trees
method = ...
tree functionality - easy to prune and cross validate
a lot of branches non a tree that looks clustered - ahve to worry about overfitting - need to prune
- need to properly prune back tree - otherwise trees will overfit --> bias, no reprociibility, bad interpretation - as going down in tree, can not tell what effects branch becasue so many branches abovve it that ALL have an effect
- assymetry bn train and testing

2/26 Lecture
1. Normality
2. contsnt variance
3. ind. obs
4. linearity

Generalizec linear models
1. "link" fxn, a fxn of ll that expresses a linear combo of explanatory variables
2. data comes from an exponential family
Decision rule C-hat:[0,1]

logisitc regression not a classifcation method by itself

How to mess it up
1. fitting when diagnostics not met - assumptions not teneble
Empirical log adds plot

Fact - for a bianry,x, the expirical log adds is guranteed to be linear
Why? - 
let P0 be sample prop of 1's corresponding to class x=0
let p1 be sample prop of 1's corresponding to x =1

Applying logistic for very small n - bias gets very small towards 0
if dimesnesions go up - bias is proportional
Asuume some sort of probalistic model
find the b-hats to make the b-hats most likey under assumption

3. curse of dimensionality - as dimensionality increases, sparser data bc more space to work with, bad w knn bc distortion will occur
4. class imbalance or training test partition that is not representable

deleting imbalances so it fits purposes - where to draw the line?

Lecture 3/1
Notions of justice - justice as equality, just deserts
equality as opportunity or outcome?
deserts as merit or need?

Financial aid - need/merit?
eqaulity - application v admission

nozeik - merit
rawls - need


Lecture 3/6
discrimination: distinguishing bn classes/ groups
arbitrary discrimination: distinguishing characteristic is irrelevant
Try to mitigate arbitrary

ex biological sex is often protected - but can be arbitrary and non-arbitrary
lack of equal opportunity
leads to (over) generalization
fairness, ethics
irrelavance, statistical can lead to blurry decesion making
inefficent

how to feel about proxies, especially when the variable it is meant to approximate is unclear?
Wether the underlying variable is ok/ wether the proxy is attainable
How effective is the proxy? a lot of things can be considered weak proxies
more info in the proxy itself (experiental proxys)
proxes have the potential to, in effect, be the same as including original user

Lecture 3/18 
- blackbox via northpoint inc
1-10 -> low medium high
- Violations
statistical parity, disparate impact, equalized odds

Is COMPAS morally defeasible?
- nothing inherently wrong. Problem is execution
- morally wrong to do predictive sentencing
 Positive feedback/ conformation bias
- overall accuracy - 65% correct class rate
- TP+TN / Total   Comparable across racial boundaries
- cost v benefit - the disadvantages of the system does not really justifiable only a 15% better than a coin flip
- Utilitarinism against
- Individual v society
- Denotology - intent (greater public safety) v effect
- Human discretion vs algorithmic discretoin
virtue v honesy -  lack of trasnparancey
- Even augmenting judge could appear - skew logistical information views each person as a data point and not a actual person
- "Accountability"
If compas was 100% correct, would it be defeasible?
- purpose of punishment? deterrent v rehabilitation
Prediction as distinct from proportionality

Doestn predict when they will re offend - it is a 2 year window

Slippery slope - you know re offense - but it is something that is legal in another state (ex weed)

NOn transparency problems
- playing system by offenders
- proxies
In S.c did not violate due process - 1. individually, 2. accurate information, only for parole, accompanied by warnings


Lecture 3/22
- informed consent: paitent/user or other moral agent providing permission for an intervention or action in light of an awareness and appreciateion of the repurcussions of that action
- Roots in biomedical ethics is both a legal and moral obligation
- laching informed consent violates the second formulation of the CI
IN all instances where informed consent is appropriate we must get it
- Tacit consent: implied consent - assumed to be given when a moral agent makes use of services that are one side of a social contract
- governed by rule of law when benefitting from society

Potential for date misuse

Objection
Is it practically feasible to get fully informed consent in all instances
surrogate consent: informed consent given on behalf of someone unable to give informed consent via a 3rd party w/ no conflcit of intrests

What happens when act of getting fully informed consent defeats the purpose of whatever action needed to be consented to in the first place?
ex. survailance

Three ways to incentivice informed consent
1. ) Cliff notes alongside full terms
2.) Compentancy check prior to consenting - quiz for terms and service can only press okay once you pass
3.) Info mediation specialist - costs money dividing line bn those who can afford it and those who cant. People who cant afford less deserving of giving full informed consent?


Lecture 4/1
Federated learning: Federated learning: a decenteralized approach to model training where by decenteralized we have loal models trained on local data, the data is not passed to a global model but parameter estimates are.

Ways that federated learning 
1.) Non - IID data
2.) we do not have to have balanced sample sizes across clients, nk can be drastically different across k=1...
3.) dat can be censored/missing

forumlation (general)
Picture of formulas  in phoitos

pk = 1/n -> iid
pk = nk/n -> no iid federated

Stochiastic gradient descent (SGD)
"Selective calculus"
Gradient if f is real
Df = (partial/x1, partial /x2,...)
Interpretation... direction of steepest ascent


Update rule for gradient prescent:
if we aim to minimize theta, thetai+1 = thetai (alpha) deltaf(thetai, xiyi)     -> tople of randomly selecting data xi-yi

set alpha too large - > overshoot minimum
set alpha too small -> takes forever


FedAve - federated average - average faderated to get gloabal,
w (t+1) = wt - m ksumk=1  nk/n deltaFk(wt) ;

w(t+1) = wt - slope (deltafk(wt))

w(t+1) = ksumk=1 nk/n 


nk total in silo, n is total points
k is superscript with w(t+1)


Federated average - what it aims to actually do
1.) optimize objective (emperical risk)
1.1) Needs to be differentiable 
2.) find global weights in each step, we local iterations w1...w2... -> w 


wt1 +wt2 + wt3 + ... /n repeat until (wt+1 - wt ~ 0)
abstract


What has this bought us in terms of data privacy?
1) never a breach in identifiable person specficic info
2.) more general able to be applied where siloing of your data is helpful
3.) Pair w differential privacy to protect even the upshots
